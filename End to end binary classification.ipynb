{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-approach",
   "metadata": {},
   "source": [
    "# 2nd Eddy Cross Disciplinary Symposium\n",
    "## An end to end Machine Learning project\n",
    "#### Predicting the geoeffectiveness of a CME\n",
    "  \n",
    "Today's workflow:\n",
    "1. Analyze data\n",
    "2. Try algorithms\n",
    "3. Evaluate results\n",
    "4. See what else can be done\n",
    "\n",
    "By the end of this meeting I hope you will understand:\n",
    "1. What the steps of a Machine Learning project are\n",
    "2. How to use tools to better analyze and visualize data\n",
    "3. The principles behind some Machine Learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-yemen",
   "metadata": {},
   "source": [
    "## The prerequisites\n",
    "### What we'll be using today:\n",
    "\n",
    "<table>\n",
    "    <th colspan=\"2\">Data Analysis</th>\n",
    "    <th colspan=\"2\">Most ML tasks</th>\n",
    "    <th colspan=\"2\">Neural Nets</th>\n",
    "    <th colspan=\"2\">Visualization</th>\n",
    "    <tr>\n",
    "        <td colspan=\"2\"><img src=\"https://miro.medium.com/max/3200/1*9v51-jsfHtk6fgAIYLoiHQ.jpeg\" alt=\"Pandas logo\" width=\"250\"/></td>\n",
    "        <td colspan=\"2\"><img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2015/01/scikit-learn-logo.png\" alt=\"Sklearn logo\" width=\"250\"/></td>\n",
    "        <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/115px-Tensorflow_logo.svg.png\" alt=\"Tensorflow logo\" height=\"250\"/></td>\n",
    "        <td><img src=\"https://miro.medium.com/max/1200/1*DKu_54iqz6C-p6ndo7rO3g.png\" alt=\"Keras logo\" width=\"250\"/></td>\n",
    "        <td colspan=\"2\"><img src=\"https://rapids.ai/assets/images/Plotly_Dash_logo.png\" alt=\"Plotly & Dash logos\" width=\"250\"/></td>\n",
    "    </tr>\n",
    "    </table>\n",
    "   \n",
    "I have linked everything at the end of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-syndication",
   "metadata": {},
   "source": [
    "**Do not worry about the following lines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (inside this environment only)\n",
    "!pip install dash\n",
    "!pip install umap-learn\n",
    "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nearby-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "killing-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure plot logging\n",
    "log_dir = \"../logs\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-focus",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "**Do not worry about this lines either.**  \n",
    "These are some functions that will help us along the way with pretty printing and plotting, mostly. Feel free to try and understand the code, but do not worry if you don't. This is not what Machine Learning is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demographic-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that plots confusion matrix\n",
    "def plot_confusion_matrix(cf_matrix):\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "              zip(group_names,group_counts)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cf_matrix, xticklabels=[0,1], yticklabels=[0,1], annot=labels, fmt='', cmap='Blues')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Function that plots the confusion matrix \n",
    "# and prints the following metrics: accuracy, recall (true positive rate), precision, true negative rate\n",
    "def evaluate_performance(actual, predicted):\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm)\n",
    "    # Compute metrics\n",
    "    # np.round(a, b) rounds a value to 2 decimals\n",
    "    accuracy = np.round(accuracy_score(actual, predicted) * 100, 2)\n",
    "    recall = np.round(recall_score(actual, predicted) * 100, 2)\n",
    "    precision = np.round(precision_score(actual, predicted) * 100, 2)\n",
    "    # Compute True Negative Rate = True Negative / (True Negative + False Positive)\n",
    "    tnr =  np.round(cm[0][0]/(cm[0][0] + cm[0][1]) * 100, 2) \n",
    "    # Print metrics\n",
    "    print(\"Accuracy: {}%\".format(accuracy))\n",
    "    print(\"Recall (True Positive Rate): {}%\".format(recall))\n",
    "    print(\"True Negative Rate: {}%\".format(tnr))\n",
    "    print(\"Precision: {}%\".format(precision))  \n",
    "    \n",
    "    \n",
    "# Function to get prediction label for binary classification\n",
    "def get_binary_prediction_type(predicted, actual):\n",
    "    if (predicted == 1 and actual == 1):\n",
    "        return 'TP'\n",
    "    if (predicted == 1 and actual == 0):\n",
    "        return 'FP'\n",
    "    if (predicted == 0 and actual == 0):\n",
    "        return 'TN'\n",
    "    if (predicted == 0 and actual == 1):\n",
    "        return 'FN'\n",
    "    return 'Unkonwn'\n",
    "\n",
    "\n",
    "# Function to create a more comprehensive prediction data frame\n",
    "def get_predictions_df(numeric_columns_used, umap_embedding, test_examples, test_labels, predicted_labels):\n",
    "    # Concatenate all given column\n",
    "    predictions_df = pd.concat([test_examples, test_labels], axis=1)\n",
    "    predictions_df['predicted'] = predicted_labels\n",
    "    # Label the predictions with their type\n",
    "    predictions_df['prediction_type'] = predictions_df.apply(lambda row: get_binary_prediction_type(row['predicted'], \n",
    "                                                                          row['geoeffective']), \n",
    "                                                                          axis=1)\n",
    "    # Add UMAP values to the dataframe\n",
    "    predictions_df['umap_0'] = umap_embedding[:, 0]\n",
    "    predictions_df['umap_1'] = umap_embedding[:, 1]\n",
    "    return predictions_df\n",
    "    \n",
    "\n",
    "    \n",
    "# Function to plot the more comprehensive prediction data umap embedded\n",
    "def plot_comprehensive_predictions_umap(df):\n",
    "    hover_columns = df.columns[~df.columns.isin(['umap_0', 'umap_1',\n",
    "                                                'geoeffective', 'prediction_type',\n",
    "                                                'predicted'])]\n",
    "    fig = px.scatter(df, x='umap_0', y='umap_1', color='prediction_type', \n",
    "                     color_discrete_sequence=[\"blue\", \"yellow\", \"green\", \"red\"],\n",
    "                     hover_data=df[hover_columns])\n",
    "    fig.show()     \n",
    "    \n",
    "    \n",
    "# Function to summarize Grid Search results\n",
    "def summarize_results(grid_result):\n",
    "    print(\"Best score: %f, using %s\\n\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    mean_f1 = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean_f1, param in zip(mean_f1, params):\n",
    "        print(\"Mean score = %f with: %r\" % (mean_f1, param))    \n",
    "\n",
    "        \n",
    "# Function to create a LogisticRegression pipeline\n",
    "def create_log_reg_pipeline(selected_features):\n",
    "    # NOTE: you can choose less features\n",
    "\n",
    "    # Create a preprocessor\n",
    "    preprocessor_standard_scaling = ColumnTransformer([\n",
    "            (\"scale\", StandardScaler(), selected_features)],\n",
    "            remainder=\"passthrough\") # allow uscaled features; 'drop' <=> do not use those columns \n",
    "\n",
    "    # Create a pipeline\n",
    "    return Pipeline([(\"preprocessor\", preprocessor_standard_scaling), \n",
    "                    (\"classifier\", LogisticRegression(random_state=seed, \n",
    "                                                     class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-victoria",
   "metadata": {},
   "source": [
    "## The task\n",
    "\n",
    "### Predict whether a CME will be geoeffective\n",
    "\n",
    "<img src=\"https://www.nasa.gov/sites/default/files/styles/full_width/public/thumbnails/image/mars_cme.gif?itok=fLhkCigJ\" alt=\"CME-NASA\" width=\"400\"/>\n",
    "\n",
    "#### Understanding the terms:  \n",
    "  \n",
    "[**CME (Coronal Mass Ejection)**](https://www.swpc.noaa.gov/phenomena/coronal-mass-ejections) = _Large expulsion of plasma and magnetic field from the Sun's corona_   \n",
    "\n",
    "[**GMS (Geomagnetic Storm)**](https://www.swpc.noaa.gov/phenomena/geomagnetic-storms) = _Major disturbance of Earth's magnetosphere_ \n",
    "\n",
    "[**Dst (index)**](https://www.swpc.noaa.gov/content/space-weather-glossary#d) = _A measure of variation in the geomagnetic field_; For this workshop, we consider that **values <=-30 (nT) indicate geomagnetic storms**.\n",
    "\n",
    "**Geoeffective** = Having the capacity to produce a GMS (i.e. **Dst <= - 30**)\n",
    "\n",
    "#### Understanding the task:  \n",
    "Having a number of solar parameters characterizing a **CME** (solar explosion), predict whether a **geomagnetic storm will occur** (Earth's magnetic field will be disturbed strongly enough that the **Dst** index value will be **<= -30**)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-complement",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assisted-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv data using pandas \n",
    "# The data is read in a DataFrame \n",
    "cmes_csv_url = 'https://raw.githubusercontent.com/andreeapricopi/cmes_ml_workshop/main/cmes.csv'\n",
    "df = pd.read_csv(cmes_csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-wallpaper",
   "metadata": {},
   "source": [
    "##### Legend:  \n",
    "**cpa** = Central Position Angle (degrees)  \n",
    "**aw** = Angular Width (degrees)   \n",
    "**lin_speed** = Linear Speed (km/s)    \n",
    "**acceleration** (m/s^2)  \n",
    "**mass** (gram)  \n",
    "**kinetic_energy** (erg)  \n",
    "**dst** = the Dst index value (nT)  \n",
    "\n",
    "Find more information about these columns [here, from the LASCO catalog](https://cdaw.gsfc.nasa.gov/CME_list/catalog_description.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-blood",
   "metadata": {},
   "source": [
    "## 1. Data exploration, analysis and preprocessing\n",
    "### Because results are as good as the data you feed to the learners\n",
    "#### And they usually only understand numbers \n",
    "We will look for:  \n",
    "   - missing values  \n",
    "   - unexpected values  \n",
    "   - correlations  \n",
    "   - distributions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary regarding the data\n",
    "# See number of missing values and data type by column\n",
    "df.info()\n",
    "# See mean, standard deviation, min, max values by column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-forward",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "1. Data cleaning\n",
    "2. Data labeling\n",
    "3. Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-female",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trying-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many missing values\n",
    "df.drop(columns = ['mass', 'kinetic_energy'], inplace=True) #inplace=True is the equivalent of df = df.drop(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exciting-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True) #inplace=True is the equivalent of df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "heavy-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Dst character values with 0\n",
    "df.dst = pd.to_numeric(df.dst.apply(lambda dst: 0 if dst == '-' else dst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-danger",
   "metadata": {},
   "source": [
    "### Data labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-developer",
   "metadata": {},
   "source": [
    "We need to create a label column based on Dst value for our binary classification.  \n",
    "Remember that Dst <= -30 means geoeffective, otherwise not geoeffective.  \n",
    "We could use True/False values for a new column called 'geoeffective', but since we would eventually still need numerical data (and therefore, we would need to encode these labels as numbers), we will create a numerical label from the beginning:\n",
    "- 0 means not geoeffective (Dst > -30)\n",
    "- 1 means geoeffective (Dst <= -30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "first-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels based on Dst value\n",
    "threshold = -30\n",
    "df['geoeffective'] = df.dst.apply(lambda dst: 0 if dst > threshold else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-wilderness",
   "metadata": {},
   "source": [
    "### Data splitting\n",
    "We need to **separate inputs** (cpa, aw, lin_speed, acceleration) from **outputs** (geoeffective label).  \n",
    "We need to **put aside a subset of data for an objective test**.  \n",
    "However, we also want to test our data after training and make improvements based on the results, so we will also have a test-like subset called **_dev_** (_development_ or also reffered to as a _validation_ set). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X (inputs; samples) and y (label; target value)\n",
    "X = df.copy()\n",
    "y = X.pop('geoeffective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geological-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Dst value\n",
    "X.drop(columns=['dst'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-involvement",
   "metadata": {},
   "source": [
    "In the following lines we will use some randomization. In order to ensure we all have the same results and that, even more importantly, you get the same results each time you run this notebook, we need to set a fixed value to feed as _random_state_. As long as you use the same value, the results will be the same.  \n",
    "Feel free to see what happens if you remove the \"random_state=seed\" lines or if you change the seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "understood-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproductibility \n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-action",
   "metadata": {},
   "source": [
    "<img src=\"train_test_split.png\" alt=\"Train-Test split\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dried-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_traindev, X_test, y_traindev, y_test = train_test_split(X, \n",
    "                                                          y, \n",
    "                                                          test_size=0.2, \n",
    "                                                          random_state=seed, \n",
    "                                                          shuffle=True,\n",
    "                                                          stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-bankruptcy",
   "metadata": {},
   "source": [
    "<img src=\"train_dev_split.png\" alt=\"Train-Dev split\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confirmed-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation (dev) sets\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_traindev, \n",
    "                                                  y_traindev, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=seed, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_traindev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-incident",
   "metadata": {},
   "source": [
    "### Data analysis & visualization\n",
    "We will not look at the test data so as not to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to have both inputs and outputs for the analysis, we will merge back again \n",
    "# X_traindev and y_traindev in a new, temporary variable\n",
    "traindev_df = pd.concat((X_traindev, y_traindev), axis=1)\n",
    "traindev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a comprehensive, auto-generated report\n",
    "profile_report = ProfileReport(traindev_df)\n",
    "profile_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-luxury",
   "metadata": {},
   "source": [
    "### Data Visualization. 2D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "antique-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get UMAP embedding (simplified, 2D data representation)\n",
    "# Initialize UMAP\n",
    "umap = UMAP(random_state=seed) # the default number of dimensions (components) is 2\n",
    "# Get the actual embeddings\n",
    "traindev_umap = umap.fit_transform(X_traindev)\n",
    "dev_umap = umap.fit_transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "explicit-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the UMAP embedding\n",
    "def plot_umap(umap_embedding, color_labels):\n",
    "    fig = px.scatter(umap_embedding, x=0, y=1, color=color_labels)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the UMAP embeddings\n",
    "plot_umap(traindev_umap, y_traindev.astype('str'))\n",
    "plot_umap(dev_umap, y_dev.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-external",
   "metadata": {},
   "source": [
    "### How does a machine learn?\n",
    "\n",
    "The machine is trying to do is <span style=\"color:green\">**discover a function**</span> that <span style=\"color:green\">**best describes**</span> the **relationship between the input and the target** value.\n",
    "  \n",
    "<span style=\"color:green\">**Discovering the function**</span>  actually means **discovering the** <span style=\"color:green\">**parameters**</span> of that function.  \n",
    "  \n",
    "For example, for a logistic regression, the function is:  \n",
    "> $ f(X) = W * X + b $, \n",
    "\n",
    "where W = [w0, w1, .., wn], X = [x0, x1, .., xn] - the features  and b is the bias.  \n",
    "  \n",
    "So <span style=\"color:green\">**training**</span> a logistic regression model means **finding the values for W and b** that result in the prediction - f(X) - being as close to the real value as possible.  \n",
    "  \n",
    "**In other words**: the model finds out how much each feature weighs so that in the future, when being presented with a series of values, it knows how to compute a prediction as accurate as possible.  \n",
    "\n",
    "<img src=\"learning.gif\" alt=\"Gif with simplified learning demo\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-deputy",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "peripheral-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "log_reg_model = LogisticRegression(random_state=seed) # use random seed for the same random weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "considerable-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict dev set values using the model\n",
    "dev_predictions = log_reg_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the predictions\n",
    "print('Accuracy: ', accuracy_score(y_dev, dev_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually compare the true values and the predicted ones\n",
    "plot_umap(dev_umap, y_dev.astype('str'))\n",
    "plot_umap(dev_umap, dev_predictions.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the recall and precision of the predictions\n",
    "print('Recall: ', recall_score(y_dev, dev_predictions)) # True Positive Rate\n",
    "print('Precision: ', precision_score(y_dev, dev_predictions)) # 1 - False Discovery Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class balance\n",
    "log_reg_balanced = LogisticRegression(class_weight='balanced', random_state=seed)\n",
    "\n",
    "# Train and predict\n",
    "log_reg_balanced.fit(X_train, y_train)\n",
    "dev_predictions = log_reg_balanced.predict(X_dev)\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_performance(y_dev, dev_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how many iterations were performed\n",
    "print('#iterations = ', log_reg_balanced.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-moscow",
   "metadata": {},
   "source": [
    "### Add feature scaling\n",
    "We will use standard scaling (i.e. substract the mean and divide by standard deviation):  \n",
    "> $ x = \\dfrac {x - mean}{std dev} $\n",
    "\n",
    "Pay attention to whether the results or the number of iterations it takes to get those results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "presidential-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add feature scaling\n",
    "# Select the features we want to use\n",
    "selected_features = X_train.columns\n",
    "\n",
    "# Create a preprocessor\n",
    "preprocessor_standard_scaling = ColumnTransformer([\n",
    "        (\"scale\", StandardScaler(), selected_features)],\n",
    "        remainder=\"drop\")\n",
    "\n",
    "# Create a pipeline\n",
    "log_reg_scaling_pipeline = Pipeline([(\"preprocessor\", preprocessor_standard_scaling), \n",
    "                                     (\"classifier\", LogisticRegression(random_state=seed, \n",
    "                                                                       class_weight='balanced'\n",
    "                                                                       ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict\n",
    "log_reg_scaling_pipeline.fit(X_train, y_train)\n",
    "dev_predictions = log_reg_scaling_pipeline.predict(X_dev)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_performance(y_dev, dev_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how many iterations were performed\n",
    "print('#iterations = ', log_reg_scaling_pipeline['classifier'].n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "starting-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive dataframe for better prediction analysis \n",
    "comprehensive_dev_df = get_predictions_df(selected_features, dev_umap, X_dev, y_dev, dev_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the newly created dataframe\n",
    "plot_comprehensive_predictions_umap(comprehensive_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what we've learned\n",
    "\n",
    "# Look at the weights \n",
    "print('W = ', log_reg_scaling_pipeline['classifier'].coef_)\n",
    "\n",
    "# Look at the bias\n",
    "print('b = ', log_reg_scaling_pipeline['classifier'].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-integral",
   "metadata": {},
   "source": [
    "### Feed Forward Artificial Neural Network\n",
    "\n",
    "### The simplified way you should imagine a neural network\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Neural_network_example.svg/330px-Neural_network_example.svg.png\" alt=\"Simplified ANN architecture\" width=\"250\">\n",
    "\n",
    " \n",
    "### A more complex neural network (containing more hidden layers)\n",
    "<img src=\"https://www.researchgate.net/profile/Chuan-Lin-3/publication/333567419/figure/fig4/AS:765686351671297@1559565260413/Construction-of-the-deep-neural-network-DNN-model.jpg\" alt=\"ANN architecture\" width=\"600\">\n",
    "\n",
    "### What's going on inside a neuron\n",
    "<img src=\"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1547672259/2_i1cdwq.png\" alt=\"Neuron\" width=\"600\"> \n",
    "\n",
    "### Some activation functions\n",
    "<img src=\"https://www.researchgate.net/profile/Junxi-Feng/publication/335845675/figure/fig3/AS:804124836765699@1568729709680/Commonly-used-activation-functions-a-Sigmoid-b-Tanh-c-ReLU-and-d-LReLU.ppm\" alt=\"Activation functions\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "civic-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of the class imbalance\n",
    "# Compute the balanced weights\n",
    "balanced_traindev_weights = compute_sample_weight('balanced', y_traindev)\n",
    "balanced_train_weights = compute_sample_weight('balanced', y_train)\n",
    "balanced_dev_weights = compute_sample_weight('balanced', y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "legendary-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care of the data scaling\n",
    "# Create the Normalization layer\n",
    "normalizer = Normalization()\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "israeli-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input shape of the model\n",
    "input_shape = X_train.shape[1:] # the number on input neurons (i.e. number of columns)\n",
    "\n",
    "# Function to create the model (build_fn)\n",
    "def create_model(input_shape, learning_rate, neurons):  \n",
    "    # Create a model that includes the normalization layer\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=input_shape)) # Specify the number of input neurons\n",
    "    model.add(normalizer)\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Configure the optimizer\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "generous-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial hyperparameters\n",
    "neurons = 1\n",
    "learning_rate = 1e-3 # How much do we change the weights after each step?\n",
    "batch_size = 32 # How many samples do we take into consideration before making a change?\n",
    "epochs = 50 # How many times do we go throught the entire data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# The following lines are for configuring where to store the tensorboard logs and how to name them\n",
    "# Do not worry if you do not understand them, they have no influence over the machine learning part\n",
    "# Create the name of the model\n",
    "model_name = \"n{}_lr{}_b{}_e{}_\".format(neurons, learning_rate, batch_size, epochs)\n",
    "# Tensorboard configurations\n",
    "log_dir = \"logs/fit/\" + model_name + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "##################################################################################################\n",
    "\n",
    "# Initialize the model\n",
    "model = create_model(input_shape=input_shape, neurons=neurons, learning_rate=learning_rate)\n",
    "\n",
    "# Fit the model on the actual trainining test\n",
    "history = model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  sample_weight=balanced_train_weights,  \n",
    "                  verbose=0,\n",
    "                  validation_split=0.2,  \n",
    "                  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the learning curves\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model\n",
    "dev_predictions = model.predict(X_dev)\n",
    "# You don't need to be concerned about the following line, it is a simple implementation detail\n",
    "# You can comment the line and see what happens without it if you're curious and try to understand the reason\n",
    "# Hint: it has to do with the last layer in the network \n",
    "dev_predictions = dev_predictions.reshape(dev_predictions.shape[0]) \n",
    "\n",
    "# Visually compare the true values and the predicted ones\n",
    "plot_umap(dev_umap, y_dev.astype('str'))\n",
    "plot_umap(dev_umap, dev_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions\n",
    "evaluate_performance(y_dev, dev_predictions >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-belly",
   "metadata": {},
   "source": [
    "### Searching for the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-surname",
   "metadata": {},
   "source": [
    "Instead of going by hand through all the options, training the model using all the combinations, testing the trained model and then looking through all the results to find the best performance, we can use an out of the box scikit-learn implementation: **GridSearch** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-bargain",
   "metadata": {},
   "source": [
    "#### Intermezzo: K-Fold Cross-Validation\n",
    "\n",
    "As hard as we try to select a representative value for the test set, there is no guarantee that we manage to do so and, therefore, the test results can be biased (either too optimistic or too pesimistic). Having more test sets could lead to a more accurate assessment. \n",
    "  \n",
    "Therefore, you could:  \n",
    "1. Split the dataset into k fold (subsets)  \n",
    "2. Train on k - 1 folds\n",
    "3. Test on the remaining fold  \n",
    "4. Repeat steps 2 and 3 k times (until you've tested the model on all k folds)  \n",
    "  \n",
    "--> The performance of your model is the mean of all k test results\n",
    "  \n",
    "An example for K = 5:\n",
    "![K-Fold Cross-Validation](https://zitaoshen.rbind.io/project/machine_learning/machine-learning-101-cross-vaildation/featured.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-creator",
   "metadata": {},
   "source": [
    "### Searching for optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-american",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Following the example below, please fill in the gap with your own hyperparameters to try. Then execute the search and look at the results (by running the other 3 cells).  \n",
    "  \n",
    "> **Example:**  \n",
    "> parameters_to_try = {  \n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "'parameter_name_1': [1, 2, 3, 4],   \n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "'parameter_name_1': ['a', 'b']   \n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "> }  \n",
    "                    \n",
    "**NOTE 1.**: The more parameters or values you add, the longer the search takes. For this workshop, please limit to a small number of possible combinations (eg: 3 parameters with 2 values each)  \n",
    "  \n",
    "**NOTE 2.**: Learning rate values are in the range (0, 1]  \n",
    "Common values for batch sizes are 16, 32, 64, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prostate-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what options you want to explore\n",
    "# Create a parameter grid\n",
    "parameters_to_try = {\n",
    "                    \n",
    "                    }\n",
    "# Hyperparameters examples: number of neurons (neurons), batch size (batch_size), \n",
    "# number of epochs (epochs), learning rate (learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-variable",
   "metadata": {},
   "source": [
    "# !\n",
    "From the cell below, **please delete the hyperparameters you want to tune**.  \n",
    "Otherwise, they will take the default value and no search will actually be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "german-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras model for GridSeeach (scikit-learn use):\n",
    "# Specify the function that creates the model (build_fn), the batch size, the number of epochs, \n",
    "# the number of neurons and learning rate\n",
    "# NOTE: KerasClassifier has a default threshold of 0.5, \n",
    "# meaning all values < 0.5 are considered 0s and all values >= 0.5 are considered 1s\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                        input_shape=input_shape,\n",
    "                        ####################################################################################\n",
    "                        ######################## TODO: DELETE HYPERPARAMETERS ##############################\n",
    "                        # !!!\n",
    "                        # Delete the lines that contain hyperparameters that you have defined in the grid\n",
    "                        # aka in the cell above (parameters_to_try)\n",
    "                        # as they will take those values.\n",
    "                        # The ones you leave here will take the default values we've specified earlier (i.e. above)\n",
    "                        neurons=neurons,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        learning_rate=learning_rate,\n",
    "                        # !!!\n",
    "                        ###################################################################################\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-harvey",
   "metadata": {},
   "source": [
    "# ?\n",
    "What metric should we use to compare 2 models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "instructional-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch configuration\n",
    "grid_search = GridSearchCV(estimator=model, \n",
    "                           param_grid=parameters_to_try, \n",
    "                           scoring=make_scorer(f1_score), # \"make_scorer\" is just an implementation detail\n",
    "                           cv=3, \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-amsterdam",
   "metadata": {},
   "source": [
    "#### After executing the code in the 2 cells below, you should see something similar to this:  \n",
    "  \n",
    "<img src=\"grid_search_example.png\" alt=\"Example of what you should see after GridSearch\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearch \n",
    "grid_search.fit(X_traindev, y_traindev, sample_weight=balanced_traindev_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the GridSearch results        \n",
    "summarize_results(grid_search)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-hampton",
   "metadata": {},
   "source": [
    "### Is this actually ok? Look at the learning curves\n",
    "Set your hyperparameters and execute the cells below to see the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set YOUR hyperparameters here (the best ones you've found with GridSearch above)\n",
    "neurons = 1\n",
    "learning_rate = 0.001 \n",
    "batch_size = 32 \n",
    "epochs = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# The following lines are for configuring where to store the tensorboard logs and how to name them\n",
    "# Do not worry if you do not understand them, they have no influence over the machine learning part\n",
    "# Create the name of the model\n",
    "model_name = \"n{}_lr{}_b{}_e{}_\".format(neurons, learning_rate, batch_size, epochs)\n",
    "# Tensorboard configurations\n",
    "log_dir = \"logs/fit/\" + model_name + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "##################################################################################################\n",
    "\n",
    "# Initialize the model\n",
    "model = create_model(input_shape=input_shape, neurons=neurons, learning_rate=learning_rate)\n",
    "\n",
    "# Fit the model on the actual trainining test\n",
    "history = model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  sample_weight=balanced_train_weights,  \n",
    "                  verbose=0,\n",
    "                  validation_split=0.2,  \n",
    "                  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the learning curves\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-priority",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-instruction",
   "metadata": {},
   "source": [
    "#### Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "phantom-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "X_traindev_poly = pd.DataFrame(poly.fit_transform(X_traindev))\n",
    "X_train_poly = pd.DataFrame(poly.fit_transform(X_train))\n",
    "X_dev_poly = pd.DataFrame(poly.fit_transform(X_dev))\n",
    "X_test_poly = pd.DataFrame(poly.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-adaptation",
   "metadata": {},
   "source": [
    "#### Test a model with polynomial features, using cross validation \n",
    "We will use a scikit-learn cross validation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fundamental-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation details\n",
    "\n",
    "# Specify the new input_shape (i.e. number of input neurons)\n",
    "input_shape=X_traindev_poly.shape[1:]\n",
    "\n",
    "# Use an appropriate normalization layer\n",
    "normalizer=Normalization()\n",
    "normalizer.adapt(np.array(X_traindev_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "healthy-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (as a KerasClassifier since we're using scikitlearn )\n",
    "model = KerasClassifier(build_fn=create_model,\n",
    "                        neurons=1,\n",
    "                        input_shape=input_shape,\n",
    "                        learning_rate=0.005,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0)\n",
    "\n",
    "# Remember how we used to supply \"sample_weight\" as a parameter to the \"fit\" methos before?\n",
    "# We need to do this again here, but since cross validation is a very general concept, \n",
    "# its implementation accepts many other parameters\n",
    "# Therefore, define 'fit_params'\n",
    "fit_parameters = {\n",
    "    'sample_weight': balanced_traindev_weights\n",
    "}\n",
    "# We want to see all metrics:\n",
    "metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score), \n",
    "    'recall': make_scorer(recall_score), \n",
    "    'precision': make_scorer(precision_score), \n",
    "    'f1': make_scorer(f1_score)\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate\n",
    "cv_results = cross_validate(model, \n",
    "                         X_traindev_poly, \n",
    "                         y_traindev, \n",
    "                         fit_params=fit_parameters,\n",
    "                         return_train_score=True,\n",
    "                         scoring=metrics) \n",
    "\n",
    "# NOTE: we can also specify k, the number of folds, by 'cv' parameter\n",
    "# By default, k = 5\n",
    "\n",
    "# Look at the results for each fold\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the means of the performance metrics\n",
    "print('---TRAIN---')\n",
    "print('Mean accuracy: ', np.mean(cv_results['train_accuracy'] * 100))\n",
    "print('Mean recall: ', np.mean(cv_results['train_recall'] * 100))\n",
    "print('Mean precision: ', np.mean(cv_results['train_precision'] * 100))\n",
    "print('---TEST---')\n",
    "print('Mean accuracy: ', np.mean(cv_results['test_accuracy'] * 100))\n",
    "print('Mean recall: ', np.mean(cv_results['test_recall'] * 100))\n",
    "print('Mean precision: ', np.mean(cv_results['test_precision'] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-sigma",
   "metadata": {},
   "source": [
    "# ?\n",
    "Are the values corresponding to training an testing similar?  \n",
    "Is that good/bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-voluntary",
   "metadata": {},
   "source": [
    "#### Test the logistic regression with polynomial features, using cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_log_reg_pipeline(X_traindev.columns)\n",
    "\n",
    "# Cross valiidate\n",
    "cv_results = cross_validate(model, X_traindev, y_traindev, scoring=metrics, return_train_score=True, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the results for each fold\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the means of the performance metrics\n",
    "print('---TRAIN---')\n",
    "print('Mean accuracy: ', np.mean(cv_results['train_accuracy'] * 100))\n",
    "print('Mean recall: ', np.mean(cv_results['train_recall'] * 100))\n",
    "print('Mean precision: ', np.mean(cv_results['train_precision'] * 100))\n",
    "print('---TEST---')\n",
    "print('Mean accuracy: ', np.mean(cv_results['test_accuracy'] * 100))\n",
    "print('Mean recall: ', np.mean(cv_results['test_recall'] * 100))\n",
    "print('Mean precision: ', np.mean(cv_results['test_precision'] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-drill",
   "metadata": {},
   "source": [
    "### Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model so far\n",
    "# best_model = #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on the entire training set (ie. traindev)\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the learning curves\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (using X_test)\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (compare to y_test)\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-south",
   "metadata": {},
   "source": [
    "## Recap\n",
    "1. A machine learning project has the following steps:\n",
    "    1. Problem definition. Data gathering\n",
    "    2. Data exploration and preprocessing\n",
    "    3. **Repeated trial and improvement**\n",
    "    4. Final testing\n",
    "2. **Training** means iterating repeatedly over the data and altering the weights to decrease the prediction error.  \n",
    "3. A **neural network** is a computational system that maps inputs to outputs. Creating it means finding the optimal hyperparameters. There is no one size fits all, experimenting is required.\n",
    "4. **Data cleaning and preprocessing** (eg: scaling, normalization) is very important\n",
    "5. **Data imbalance** is a serious issue and must be addressed for good results\n",
    "6. The **metrics** we use are important (eg: some can be misleading)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-patent",
   "metadata": {},
   "source": [
    "##### What did we use today?\n",
    "- [pandas](https://pandas.pydata.org/), together with [pandas-profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/)  \n",
    "- [NumPy](https://numpy.org/)  \n",
    "- [scikit-learn](https://scikit-learn.org/stable/)  \n",
    "- [TensorFlow](https://www.tensorflow.org/overview)  \n",
    "- [Keras](https://keras.io/)  \n",
    "- [UMAP](https://umap-learn.readthedocs.io/en/latest/)  \n",
    "- [Plotly](https://plotly.com/python/)\n",
    " \n",
    "##### Want to know more?\n",
    "Besides scikit-learn, Tensorflow and Keras' websites, which include nice tutorials, I recommend this book:  \n",
    "[Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow, 2nd Edition, by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) as well as this blog: [machinelearningmastery.com](https://machinelearningmastery.com/blog/)\n",
    "    \n",
    "  \n",
    "    \n",
    "**Contact**: andreeapricopi@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
